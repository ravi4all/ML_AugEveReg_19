{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# 1. Tokenization\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "# 2. Removing Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "# 3. Stemming/Lemmatization\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "# 4. Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"Hello Ram, How are you ? I was planning to watch a cricket match...\",\n",
    "    \"Virat kohli is captain of indian cricket team. Indian cricket has improved a lot\",\n",
    "    \"Sachin and Dhoni Played very well in last two matches, greatest innings ever...\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_tokenize(data[0])\n",
    "for i in range(len(data)):\n",
    "    data[i] = word_tokenize(data[i].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'ram', ',', 'how', 'are', 'you', '?', 'i', 'was', 'planning', 'to', 'watch', 'a', 'cricket', 'match', '...']\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "myStopwords = [',','...','?','.']\n",
    "s = stopwords.words('english')\n",
    "s.extend(myStopwords)\n",
    "\n",
    "words = []\n",
    "for itemList in data:\n",
    "    wordList = []\n",
    "    for word in itemList:\n",
    "        if word not in s:\n",
    "            wordList.append(word)\n",
    "    words.append(wordList)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'ram', 'planning', 'watch', 'cricket', 'match']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play\n",
      "greatest\n",
      "watch\n",
      "hate\n",
      "love\n",
      "love\n",
      "went\n",
      "bought\n"
     ]
    }
   ],
   "source": [
    "demo = ['played','greatest','watched','hated','loved','loving','went','bought']\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "for word in demo:\n",
    "    print(ps.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "played ====> play\n",
      "greatest ====> greatest\n",
      "watched ====> watch\n",
      "hated ====> hat\n",
      "loved ====> love\n",
      "loving ====> love\n",
      "went ====> go\n",
      "bought ====> buy\n"
     ]
    }
   ],
   "source": [
    "wnet = WordNetLemmatizer()\n",
    "for word in demo:\n",
    "    print(wnet.lemmatize(word,pos='n'),\"====>\",wnet.lemmatize(word,pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(words)):\n",
    "    for j in range(len(words[i])):\n",
    "        words[i][j] = wnet.lemmatize(words[i][j],pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'ram', 'plan', 'watch', 'cricket', 'match']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['virat', 'kohli', 'captain', 'indian', 'cricket', 'team', 'indian', 'cricket', 'improve', 'lot']\n"
     ]
    }
   ],
   "source": [
    "print(words[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sachin', 'dhoni', 'play', 'well', 'last', 'two', 'match', 'greatest', 'innings', 'ever']\n"
     ]
    }
   ],
   "source": [
    "print(words[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(words)):\n",
    "    words[i] = ' '.join(words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello ram plan watch cricket match',\n",
       " 'virat kohli captain indian cricket team indian cricket improve lot',\n",
       " 'sachin dhoni play well last two match greatest innings ever']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = cv.fit(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hello': 5, 'ram': 15, 'plan': 13, 'watch': 20, 'cricket': 1, 'match': 12, 'virat': 19, 'kohli': 9, 'captain': 0, 'indian': 7, 'team': 17, 'improve': 6, 'lot': 11, 'sachin': 16, 'dhoni': 2, 'play': 14, 'well': 21, 'last': 10, 'two': 18, 'greatest': 4, 'innings': 8, 'ever': 3}\n"
     ]
    }
   ],
   "source": [
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_transform = cv.transform(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x22 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 24 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 2, 0, 0, 0, 0, 1, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_transform.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello ram plan watch cricket match', 'virat kohli captain indian cricket team indian cricket improve lot', 'sachin dhoni play well last two match greatest innings ever']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = tfidf.transform(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.3349067 , 0.        , 0.        , 0.        ,\n",
       "        0.44036207, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.3349067 , 0.44036207, 0.        ,\n",
       "        0.44036207, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.44036207, 0.        ],\n",
       "       [0.2849755 , 0.43346242, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.2849755 , 0.56995099, 0.        , 0.2849755 ,\n",
       "        0.        , 0.2849755 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.2849755 , 0.        , 0.2849755 ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.32311233, 0.32311233, 0.32311233,\n",
       "        0.        , 0.        , 0.        , 0.32311233, 0.        ,\n",
       "        0.32311233, 0.        , 0.24573525, 0.        , 0.32311233,\n",
       "        0.        , 0.32311233, 0.        , 0.32311233, 0.        ,\n",
       "        0.        , 0.32311233]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
